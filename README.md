This is an Image-Text classfication model, built using CLIP, an open-source model by openAI
It has a text encoder and an Image Encoder (VIT of ResNet CNN's) that create a joint embedding of the text & image vectors 
This particular project uses the ViT Image encoder.
What makes this a good model?  1. Joint Embedding 2. Contrastive Learning technique that was used to train this model 3. Recognises various elements in an image 4. Used in object detection
